{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "\n",
    "## Where We Are\n",
    "Representing Information\n",
    "Functional Programming\n",
    "Object-Oriented Programming\n",
    "File I/O\n",
    "Where We Are In The Course: File I/O\n",
    "Where We Are In The Course\n",
    "\n",
    "## What We're Doing\n",
    "Principles of File I/O: File systems; the pathlib module; and Path-like objects\n",
    "Plain Text: What are file-like objects; how to responsibly open (and close) files; and how to read data from and write data to external files\n",
    "JSON: What is JSON; loading JSON data from a file into Python; dumping data from Python into a file\n",
    "CSV: What is CSV; reading CSV data from a file into Python; writing data from Python to a file.\n",
    "Lesson Overview: We'll learn about File I/o Principles, Plain Text, JSON and CSV\n",
    "Lesson Overview\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you will be able to:\n",
    "\n",
    "Read and write generic data from and to external files\n",
    "Use the JSON library to load and dump JSON-formatted data\n",
    "Use the CSV library to load and dump CSV-formatted data\n",
    "Combine all of the techniques we've seen to create advanced programs\n",
    "\n",
    "## Files, Formats, and Structured Data\n",
    "Data at rest are stored in files.\n",
    "File extensions can inform us about the structure of the content within.\n",
    "To connect Python to a file, we open a file object.\n",
    "Remember, files can come from anywhere – your computer, a network, even the cloud!\n",
    "The Big Picture: Extract, Transform, Load\n",
    "The Big Picture: Extract, Transform, Load\n",
    "\n",
    "## The Big Picture\n",
    "When working with files, it's nice to think about it in three steps:\n",
    "\n",
    "Extract data from files into Python\n",
    "Transform the data - according to whatever it is you actually want to do - within Python\n",
    "Write the data from Python back to a file.\n",
    "Data flows into and out of Python through file-like objects - Python objects that can connect to the external filesystem.\n",
    "\n",
    "## Applications of File I/O\n",
    "Consume external data (large data sets)\n",
    "Produce external results (machine learning models, analyses)\n",
    "Abstractly, model the consumption and production of data\n",
    "\n",
    "## New Terms\n",
    "Term\tDefinition\n",
    "File\tA logical collection of digital information into a single unit.\n",
    "File System\tThe mechanism by which an digital system divides its memory into an organized collection of logical files.\n",
    "File Type\tThe specific format with which a file's data should be interpreted, often implicit in the file's extension or data.\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_file_formats\n",
    "https://simple.wikipedia.org/wiki/File_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Systems and Paths\n",
    "\n",
    "Python's built-in pathlib module provides object-oriented filesystem paths\n",
    "## pathlib\n",
    "\n",
    "Python's built-in pathlib module provides object-oriented filesystem paths, and it's a useful introduction to thinking about the layout of files on a filesystem.\n",
    "\n",
    "There are loads of useful things you can do with Paths (the documentation page is well-worth reading) but you'll be able to get by with the following pieces of functionality:\n",
    "\n",
    "here = Path('.')  # Get an instance of a Path subclass describing the interpreter's current location (which is usually, but not necessarily, the directory containing your Python files).\n",
    "here = here.resolve()  # Resolve symbolic links and `..` segments into an absolute `Path`.\n",
    "parent = here.parent  # Navigate up the chain of parents. A purely lexical operation, so it's important to call `.resolve()` or a similar method first.\n",
    "child = here / 'subfolder' / 'subfile.txt'  # Navigate to a subfolder or subfile. Hooray for magic methods (`__div__`) and polymorphism!\n",
    "To reiterate, the important concept is that files are organized on a filesystem through nested directories (\"folders\"), with a specific file path from the root folder or a drive. The important detail is that Python's pathlib module provides good tools for working with files and file paths.\n",
    "\n",
    "## Plain Text Files\n",
    "\n",
    "The general pattern for reading and writing plain text from files is:\n",
    "\n",
    "Extract data from a file into Python\n",
    "Open a file-like object f\n",
    "Call f.read() or a similar method\n",
    "Do something with the data, now within Python\n",
    "Write data from Python to a file.\n",
    "Open a file-like object f\n",
    "Call f.write(line) or a similar method\n",
    "Plain Text File I/O diagram\n",
    "Plain Text File I/O\n",
    "\n",
    "## Opening a File\n",
    "The open function in Python can open a file-like object from a path-like object, for reading, writing, or perhaps both (there are a few more flags as well).\n",
    "\n",
    "with open(filepath, mode) as f:\n",
    "    # Use the file-like object `f`\n",
    "    ...\n",
    "The mode can be 'r' for reading, or 'w' for writing, and there are a few other options too.\n",
    "\n",
    "The new syntax of the with statement ensures that the opened file-like object will be closed when we exit the block - it's good hygiene when working with resources like files. It's roughly equivalent to:\n",
    "\n",
    "try:\n",
    "    f = open(filepath, mode)\n",
    "    # Use the file-like object `f`\n",
    "    ...\n",
    "finally:\n",
    "    f.close()\n",
    "In this way, even if an error occurs in the body, Python will make sure to immediately close the file object.\n",
    "\n",
    "## QUIZ QUESTION\n",
    "Which of the following is the most appropriate syntax to open named my-outfile-file.txt for writing and write the string \"Hello, world!\" to it?\n",
    "\n",
    "# (A)\n",
    "with open('my-outfile-file.txt', 'w') as outfile: \n",
    "    outfile.write(\"Hello, world!\")\n",
    "\n",
    "# (B)\n",
    "outfile = open('my-outfile-file.txt', 'w'): \n",
    "outfile.write(\"Hello, world!\")\n",
    "# Oops! We forgot to close the file.\n",
    "\n",
    "Answer = A\n",
    "\n",
    "\n",
    "Example\n",
    "Suppose that we have a file queries.txt:\n",
    "\n",
    "python programmer\n",
    "UDACITY\n",
    "Web developer\n",
    "\n",
    "and that we wish to write a program that will normalize the queries in this file by lowercasing them all and removing the extra lines between each query.\n",
    "\n",
    "# (1) Extract data from the `queries.txt` file into Python.\n",
    "with open('queries.txt', 'r') as infile:\n",
    "    contents = infile.read()  # Read one big string - the contents of this file.\n",
    "\n",
    "\n",
    "# (2) Transform the data within Python.\n",
    "queries = contents.split('\\n')  # Split the string into a list by line breaks.\n",
    "normalized = [query.strip().lower() for query in queries[::2]]  # Normalize each query with the stripped, lowercased version of every other line.\n",
    "\n",
    "# (3) Write the normalized queries out to a file.\n",
    "with open('normalized-queries.txt', 'w') as outfile:\n",
    "    for query in normalized:\n",
    "        outfile.write(query + '\\n')  # It might be better to use outfile.writelines here, but let's practice `.write`-ing strings.\n",
    "QUIZ QUESTION\n",
    "Suppose that we open a file f with the 'r' mode. What is the type of the object returned by f.read()?\n",
    "\n",
    "str\n",
    "\n",
    "New Terms\n",
    "Term\tDefinition\n",
    "File Mode\tThe mode in which a file-like object is opened, including 'r' (for reading, the default) or 'w' for writing.\n",
    "File-like Object\tAn object that behaves as a file, that can perhaps be read from, written to, or more.\n",
    "Path-like Object\tAn object that behaves like a Path, in that it can identity a file path.\n",
    "Plain Text\tA file format that interprets binary data as plain text values.\n",
    "The open keyword\tA built-in function that opens a file-like object at a path.\n",
    "The pathlib module\tA built-in module that provides object-oriented filesystem paths.\n",
    "The with keyword\tA keyword that introduces a context manager for managing resources, such as automatically closing a file.\n",
    "\n",
    "Further Reading\n",
    "open: The built-in open function.\n",
    "\n",
    "https://www.w3schools.com/python/python_file_handling.asp\n",
    "\n",
    "https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files\n",
    "\n",
    "https://docs.python.org/3/library/io.html#io-overview\n",
    "\n",
    "https://docs.python.org/3/library/pathlib.html\n",
    "\n",
    "https://www.educative.io/edpresso/the-with-statement-in-python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "\n",
    "In this exercise, you'll write a function count_unique_words that prints the ten most common unique words from a text file.\n",
    "\n",
    "def count_unique_words(filename):\n",
    "    ...\n",
    "Concretely, we'll be using hamlet.txt, a text file containing the full text of \"The Tragedy of Hamlet, Prince of Denmark\" released by Project Gutenberg under their license.\n",
    "\n",
    "Your output might look like:\n",
    "\n",
    "the 1109\n",
    "and 763\n",
    "of 735\n",
    "to 673\n",
    "I 514\n",
    "a 499\n",
    "in 455\n",
    "my 443\n",
    "you 423\n",
    "HAMLET. 359\n",
    "We won't worry too much about punctuation, capitalization, or other nuances of language. For this exercise, it's safe to say that, given a line of text from a text file, the \"words\" within that line are the elements that result when you split the line on any whitespace.\n",
    "\n",
    "Hint: This will be significantly easier if you use a data type from Python's built-in collections module - collections.Counter. You can read more about collections.Counter in the Python documentation - https://docs.python.org/3/library/collections.html#collections.Counter \n",
    "\n",
    "License\n",
    "This eBook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away, or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.org. If you are not located in the United States, you'll have to check the laws of the country where you are located before using this ebook.http://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "JSON Format\n",
    "JSON stands for \"Javascript Object Notation\", and is a file format for encoding structured data.\n",
    "\n",
    "JSON elements include text, numbers, booleans, and nothingness (like str, int/float, bool, and NoneType), as well as the (sequence) aggregate array (like Python's list) and the (associative) aggregate object (like Python's dict).\n",
    "\n",
    "Let's look at some example files:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"class\": \"Iris-setosa\",\n",
    "    \"petallength\": 1.4,\n",
    "    \"petalwidth\": 0.2,\n",
    "    \"sepallength\": 5.1,\n",
    "    \"sepalwidth\": 3.5\n",
    "  },\n",
    "  {\n",
    "    \"class\": \"Iris-versicolor\",\n",
    "    \"petallength\": 4.7,\n",
    "    \"petalwidth\": 1.4,\n",
    "    \"sepallength\": 7,\n",
    "    \"sepalwidth\": 3.2\n",
    "  },\n",
    "  {\n",
    "    \"class\": \"Iris-virginica\",\n",
    "    \"petallength\": 6,\n",
    "    \"petalwidth\": 2.5,\n",
    "    \"sepallength\": 6.3,\n",
    "    \"sepalwidth\": 3.3\n",
    "  }\n",
    "]\n",
    "The above file represents an array of objects, each of which represents a particular flower. Each of these flowers has a class, a petal length and width, and a sepal length and width.\n",
    "\n",
    "How about the information in a tweet?\n",
    "\n",
    "{\n",
    "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
    "  \"id_str\": \"850006245121695744\",\n",
    "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
    "  \"user\": {\n",
    "    \"id\": 2244994945,\n",
    "    \"name\": \"Twitter Dev\",\n",
    "    \"screen_name\": \"TwitterDev\",\n",
    "    \"location\": \"Internet\",\n",
    "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
    "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
    "  },\n",
    "  \"place\": {\n",
    "  },\n",
    "  \"entities\": {\n",
    "    \"hashtags\": [\n",
    "    ],\n",
    "    \"urls\": [\n",
    "      {\n",
    "        \"url\": \"https:\\/\\/t.co\\/XweGngmxlP\",\n",
    "        \"unwound\": {\n",
    "          \"url\": \"https:\\/\\/cards.twitter.com\\/cards\\/18ce53wgo4h\\/3xo1c\",\n",
    "          \"title\": \"Building the Future of the Twitter API Platform\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"user_mentions\": [\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "This is a much more highly-structured object, but the idea is the same.\n",
    "\n",
    "Even Nobel prizes can be represented in a JSON format:\n",
    "\n",
    "{\n",
    "  \"prizes\": [\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"chemistry\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"991\",\n",
    "          \"firstname\": \"Emmanuelle\",\n",
    "          \"surname\": \"Charpentier\",\n",
    "          \"motivation\": \"\\\"for the development of a method for genome editing\\\"\",\n",
    "          \"share\": \"2\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"992\",\n",
    "          \"firstname\": \"Jennifer A.\",\n",
    "          \"surname\": \"Doudna\",\n",
    "          \"motivation\": \"\\\"for the development of a method for genome editing\\\"\",\n",
    "          \"share\": \"2\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"economics\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"995\",\n",
    "          \"firstname\": \"Paul\",\n",
    "          \"surname\": \"Milgrom\",\n",
    "          \"motivation\": \"\\\"for improvements to auction theory and inventions of new auction formats\\\"\",\n",
    "          \"share\": \"2\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"996\",\n",
    "          \"firstname\": \"Robert\",\n",
    "          \"surname\": \"Wilson\",\n",
    "          \"motivation\": \"\\\"for improvements to auction theory and inventions of new auction formats\\\"\",\n",
    "          \"share\": \"2\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"literature\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"993\",\n",
    "          \"firstname\": \"Louise\",\n",
    "          \"surname\": \"Gl\\u00fcck\",\n",
    "          \"motivation\": \"\\\"for her unmistakable poetic voice that with austere beauty makes individual existence universal\\\"\",\n",
    "          \"share\": \"1\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"peace\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"994\",\n",
    "          \"motivation\": \"\\\"for its efforts to combat hunger, for its contribution to bettering conditions for peace in conflict-affected areas and for acting as a driving force in efforts to prevent the use of hunger as a weapon of war and conflict\\\"\",\n",
    "          \"share\": \"1\",\n",
    "          \"firstname\": \"World Food Programme\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"physics\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"988\",\n",
    "          \"firstname\": \"Roger\",\n",
    "          \"surname\": \"Penrose\",\n",
    "          \"motivation\": \"\\\"for the discovery that black hole formation is a robust prediction of the general theory of relativity\\\"\",\n",
    "          \"share\": \"2\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"989\",\n",
    "          \"firstname\": \"Reinhard\",\n",
    "          \"surname\": \"Genzel\",\n",
    "          \"motivation\": \"\\\"for the discovery of a supermassive compact object at the centre of our galaxy\\\"\",\n",
    "          \"share\": \"4\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"990\",\n",
    "          \"firstname\": \"Andrea\",\n",
    "          \"surname\": \"Ghez\",\n",
    "          \"motivation\": \"\\\"for the discovery of a supermassive compact object at the centre of our galaxy\\\"\",\n",
    "          \"share\": \"4\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"year\": \"2020\",\n",
    "      \"category\": \"medicine\",\n",
    "      \"laureates\": [\n",
    "        {\n",
    "          \"id\": \"985\",\n",
    "          \"firstname\": \"Harvey\",\n",
    "          \"surname\": \"Alter\",\n",
    "          \"motivation\": \"\\\"for the discovery of Hepatitis C virus\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"986\",\n",
    "          \"firstname\": \"Michael\",\n",
    "          \"surname\": \"Houghton\",\n",
    "          \"motivation\": \"\\\"for the discovery of Hepatitis C virus\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        },\n",
    "        {\n",
    "          \"id\": \"987\",\n",
    "          \"firstname\": \"Charles\",\n",
    "          \"surname\": \"Rice\",\n",
    "          \"motivation\": \"\\\"for the discovery of Hepatitis C virus\\\"\",\n",
    "          \"share\": \"3\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "]\n",
    "## Attribution\n",
    "The Iris dataset comes from UCI's ML Repository.\n",
    "\n",
    "Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "The tweet data comes from Twitter's Developer Docs.https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/intro-to-tweet-json\n",
    "\n",
    "The Nobel prize data comes from their v1 API http://api.nobelprize.org/v1/prize.json and is governed by their Terms of Use,https://www.nobelprize.org/about/terms-of-use-for-api-nobelprize-org-and-data-nobelprize-org/ \n",
    "\n",
    "Reddit provides JSON-formatted data.\n",
    "\n",
    "If we loaded the contents of https://www.reddit.com/r/all/top.json?t=all into a Python object named content using json.load, which of the following expressions would construct a list of the top post titles?\n",
    "\n",
    "You'll have to actually take a look at the JSON file at the above link.\n",
    "\n",
    "Answer\n",
    "[child[\"data][\"title\"]for child in content[\"data\"][\"children\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With JSON\n",
    "\n",
    "The general pattern is similar to before\n",
    "\n",
    "The general pattern for reading and writing plain text from files is:\n",
    "\n",
    "Extract data from a JSON file into Python\n",
    "Open a file-like object f\n",
    "Call json.load(f) or a similar method\n",
    "Do something with the data, now within Python\n",
    "Write data from Python to a file.\n",
    "Open a file-like object f\n",
    "Call json.dump(obj, f) or a similar method\n",
    "Working with JSON Data\n",
    "Working with JSON Data\n",
    "\n",
    "Suppose that we have the file listings.json of job listings:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Udacity\",\n",
    "        \"role\": 100,\n",
    "        \"description\": \"A stellar Python instructor is needed for a new course!\",\n",
    "        \"available\": true\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Udacity\",\n",
    "        \"role\": 404,\n",
    "        \"description\": \"A quality assistance engineer who can start immediately.\",\n",
    "        \"available\": false\n",
    "    }\n",
    "]\n",
    "and we want to write a program that will only keep available jobs.\n",
    "\n",
    "import json\n",
    "\n",
    "# Extract data into Python\n",
    "with open('listings.json', 'r') as infile:\n",
    "    contents = json.load(infile)  # Parse JSON data into a Python object. (A)\n",
    "\n",
    "# Filter out all unavailable job listings.\n",
    "available = [job for job in contents if job[\"available\"]]\n",
    "\n",
    "# Write available listings to an output file.\n",
    "with open('available-listings.json', 'w') as outfile:\n",
    "    json.dump(available, outfile, indent=2)\n",
    "\n",
    "New Terms\n",
    "Term\tDefinition\n",
    "JSON\tA standard format for encoding structured data, often thought of as (nested) sequences and mappings.\n",
    "The json module\tA built-in module that provides a JSON encoder and decoder through the json.dump and json.load functions.\n",
    "\n",
    "https://en.wikipedia.org/wiki/JSON\n",
    "https://www.json.org/json-en.html\n",
    "https://docs.python.org/3/library/json.html\n",
    "https://realpython.com/python-json/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV I/O\n",
    "\n",
    "CSV Format\n",
    "CSV stands for comma-separated values. It can be thought of as an Excel spreadsheet, with row representing objects and columns representing attributes.\n",
    "\n",
    "Examples\n",
    "A CSV file might contain information about countries (from Google)\n",
    "\n",
    "country,latitude,longitude,name\n",
    "AD,42.546245,1.601554,Andorra\n",
    "AE,23.424076,53.847818,United Arab Emirates\n",
    "AF,33.93911,67.709953,Afghanistan\n",
    "AG,17.060816,-61.796428,Antigua and Barbuda\n",
    "AI,18.220554,-63.068615,Anguilla\n",
    "or even information about airports (from (OpenFlights)[https://openflights.org/data.html]):\n",
    "\n",
    "1,\"Goroka Airport\",\"Goroka\",\"Papua New Guinea\",\"GKA\",\"AYGA\",-6.081689834590001,145.391998291,5282,10,\"U\",\"Pacific/Port_Moresby\",\"airport\",\"OurAirports\"\n",
    "2,\"Madang Airport\",\"Madang\",\"Papua New Guinea\",\"MAG\",\"AYMD\",-5.20707988739,145.789001465,20,10,\"U\",\"Pacific/Port_Moresby\",\"airport\",\"OurAirports\"\n",
    "3,\"Mount Hagen Kagamuga Airport\",\"Mount Hagen\",\"Papua New Guinea\",\"HGU\",\"AYMH\",-5.826789855957031,144.29600524902344,5388,10,\"U\",\"Pacific/Port_Moresby\",\"airport\",\"OurAirports\"\n",
    "Notice that in the latter cases, there was no header row, so it was harder to interpret the data.\n",
    "\n",
    "## Working with CSV Data\n",
    "The general pattern is similar to before, but there's an extra step to read data or to write data.\n",
    "\n",
    "Extract data from a CSV file into Python\n",
    "Open a file-like object f\n",
    "Create a csv.reader (or a csv.DictReader with extra information for headers)\n",
    "Consume each line of the csv.reader\n",
    "Do something with the data, now within Python\n",
    "Write data from Python to a file.\n",
    "Open a file-like object f\n",
    "Create a csv.writer (or a csv.DictWriter with extra information for headers)\n",
    "Write each line to the csv.writer\n",
    "Working with CSV Data using reader and writer\n",
    "Working with CSV Data\n",
    "\n",
    "csv.reader and csv.writer\n",
    "\n",
    "Suppose we have a CSV file containing wage information:\n",
    "\n",
    "id,title,annual_wage\n",
    "100,Instructor,12000\n",
    "101,Lecturer,16000\n",
    "102,Professor,20000\n",
    "200,Salesperson,40000\n",
    "404,Quality Assurance,30000\n",
    "500,Backend Engineer,50000\n",
    "512,\"Product Lead, Eng\",80000\n",
    "808,Musician,25000\n",
    "999,Accountant,60000\n",
    "and we want to process this so that it contains just entries with a sufficiently high wage.\n",
    "\n",
    "high_wages = []\n",
    "desired_wage = 40000\n",
    "\n",
    "with open('wages.csv', 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    next(reader)  # Skip the header line.\n",
    "    for row in reader:\n",
    "        annual_wage = int(row[2])  # (A)\n",
    "        if annual_wage >= desired_wage:\n",
    "            high_wages.append(row)\n",
    "\n",
    "with open('high-wages.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    for row in high_wages:\n",
    "        writer.writerow(row)\n",
    "csv.DictReader and csv.DicWriter\n",
    "Play Video\n",
    "When it comes to CSV, it can be nice to keep track of the headers of your data. The usual csv.reader and csv.writer objects aren't very wise to headers, so Python also provides csv.DictReader and csv.DictWriter.\n",
    "\n",
    "For reading, if you substitute csv.DictReader for csv.reader, the reader will attempt to interpret a header row, and provides dictionaries (mapping column header names to values) rather than the sequential-type rows of csv.reader.\n",
    "\n",
    "desired_wage = 40000\n",
    "high_wages = []\n",
    "with open('wages.csv', 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for elem in reader:\n",
    "        print(elem)  # <= Each of these elements are `dict`s, not `list`s!\n",
    "        if int(elem['annual_wage']) >= desired_wage:\n",
    "            high_wages.append(elem)\n",
    "\n",
    "# Now, high_wages is a list of dicts, which is helpful because each dict knows the meaning of each of its values!\n",
    "For writing, the story is a bit more complex - you need to pass an iterable of fieldnames to the constructor, and include a writer.writeheader() line (to explicitly write a header):\n",
    "\n",
    "with open('high-wages-with-header.csv', 'w') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=high_wages[0].keys())\n",
    "    writer.writeheader()\n",
    "    for elem in high_wages:\n",
    "        writer.writerow(elem)  # Notice that we're passing a dict to writerow.\n",
    "\n",
    "\n",
    "New Terms\n",
    "Term\tDefinition\n",
    "CSV\tA standard format for encoding structured data in rows, with an optional header.\n",
    "The csv module\tA built-in module for reading and writing CSV files with csv.reader/csv.writer and csv.DictReader/csv.DictWriter\n",
    "Further Reading\n",
    "CSV (Wiki): A formal definition of the CSV format.\n",
    "Reading and Writing CSV Files in Python: A great overview of using CSV data in Python, including touching on the pandas library.\n",
    "The csv module: A Python module for reading and writing CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O Errors\n",
    "\n",
    "The data within the file is corrupted, and a format-specific reader (e.g. json.load) is unable to parse the data into a structured format.\n",
    "\n",
    "There is no file on the filesystem at the given path, perhaps because its been moved or renamed, or perhaps because the programmer made a small typo.\n",
    "\n",
    "The specific conditions of the filesystem make the file inaccessible, broken, or disconnected.\n",
    "\n",
    "Whenever Python connects to the outside world, things can go awry. File I/O errors are plentiful, but many often fall into the following categories:\n",
    "\n",
    "Missing: Python can't find the file, either because it doesn't exist or because the file path doesn't correctly point to the desired file.\n",
    "Corrupt: The data within the file is formatted incorrectly - perhaps you've tried to read data in a CSV format as if it were JSON data, which will fail.\n",
    "Broken: Something has gone wrong with Python's connection to the file, and it's lost its connection to the underlying file-like object.\n",
    "\n",
    "## File-like objects\n",
    "So far, we've thought of files in Python as actual files that live on your filesystem. That's not necessarily the case. Any object that behaves sufficiently like a file can be used in the places we've seen files. Usually, this acts-like-a-file object is either some networked connection to a file in a faraway land, like a socket connection or \"the cloud,\" or an in-memory buffer, that might make a string act like a file. Python's documentation on the io module has more great information on working with streams.\n",
    "\n",
    "## Reading and Writing bytes\n",
    "So far, we've imagined that the 1s and 0s within a file correspond to text, that could interpret in some meaningful way – JSON, CSV, etc. Sometimes, the 1s and 0s don't direct correspond to text, but rather represent binary data - perhaps an image, or an audio file. The Python type to hold binary data is bytes, and file-like objects can be opened to read or write binary data (bytes) with the b mode (i.e. 'rb' or 'wb'.\n",
    "\n",
    "## New Terms\n",
    "Term\tDefinition\n",
    "bytes\tA representation of binary data, similar to str, usually from files opened in a binary mode ('b').\n",
    "Further Reading\n",
    "File I/O in Python: Details and advanced tactics of file I/O in Python.\n",
    "StringIO, BytesIO, and file-like objects: Examples of using tools for working with unusual types of streams.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
